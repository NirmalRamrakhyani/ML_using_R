confusionMatrix.train(ada.down.model)
varImp(ada.down.model)
#plot(varImp(ada.down.model), main = "Variable importance from Adaboost with down sample", col = 2, lwd = 2)
#rf.smote.model$finalModel #rf.smote.model$results
print(rf.smote.model)
confusionMatrix.train(rf.smote.model)
rf.smote.model$bestTune
varImp(rf.smote.model)
print(rf.down.model)
confusionMatrix.train(rf.down.model)
varImp(rf.down.model)
View(data.test)
model.train <- data.train[,-c(8)]
for (i in c(9:30)) {
if (is.ordered(model.train[,i])) {
model.train[,i] <- factor(model.train[,i], ordered = FALSE)
}
}
if (is.ordered(model.train[,32])) {
model.train[,32] <- factor(model.train[,32], ordered = FALSE)
}
str(model.train)
model.test <- data.test[,-c(8)]
for (i in c(9:30)) {
if (is.ordered(model.test[,i])) {
model.test[,i] <- factor(model.test[,i], ordered = FALSE)
}
}
if (is.ordered(model.test[,32])) {
model.test[,32] <- factor(model.test[,32], ordered = FALSE)
}
View(model.train)
model.train <- data.train[,-c(8)]
for (i in c(9:43)) {
if (is.ordered(model.train[,i])) {
model.train[,i] <- factor(model.train[,i], ordered = FALSE)
}
}
if (is.ordered(model.train[,45])) {
model.train[,45] <- factor(model.train[,45], ordered = FALSE)
}
str(model.train)
model.test <- data.test[,-c(8)]
for (i in c(9:43)) {
if (is.ordered(model.test[,i])) {
model.test[,i] <- factor(model.test[,i], ordered = FALSE)
}
}
if (is.ordered(model.test[,45])) {
model.test[,45] <- factor(model.test[,45], ordered = FALSE)
}
for (i in c(1:45)) {
id = 0
if (is.factor(model.test[,i])) {
#id <- which(!(model.test[,i] %in% levels(model.train[,i])))
#model.test[,i][id] <- NA
model.test[,i] <- factor(model.test[,i], levels = levels(model.train[,i]))
}
}
#To remove new levels from test set
id <- which((model.test$NS_NURSEPROACTIVENESS == "1"))
model.test$NS_NURSEPROACTIVENESS[id] <- NA
model.test <- na.omit(model.test)
str(model.test)
objControl <- trainControl(method='cv', number = 3,
returnResamp='none',
summaryFunction = twoClassSummary,
savePredictions = TRUE,
classProbs = TRUE,
sampling = "down")#, p = 0.70) #in case method = #"LGOCV"
set.seed(4121)
rf.down.model <- train(model.train[,1:44], model.train[,45],
method='rf',
trControl=objControl,
metric = "ROC",ntree = 1024,
prox=TRUE,allowParallel=TRUE)
print(rf.down.model)
confusionMatrix.train(rf.down.model)
varImp(rf.down.model)
trainPredictedClass <- predict(rf.down.model, model.train, type = "raw")
confusionMatrix(trainPredictedClass,model.train$NPS_Status)
testPredictedClass <- predict(rf.down.model, model.test, type = "raw")
confusionMatrix(testPredictedClass,model.test$NPS_Status)
library(caret)            #for split and model accuracy
library(ROCR)
library(fastAdaboost)     #to use the get_tree()
library(rattle)           #print the business rules for ensemble models
library(inTrees)          #to extract the business rules from random forest
library(plyr)
library(Matrix)           #spare matrix
library(grid)             #sparse matrix
library(DMwR)             #smote sampling
library(randomForest)     #random forest
library(nnet)             #neural network
library(adabag)           #adaboost
library(MASS)
raw.train.data <- read.csv("/Users/Rahul/Documents/Rahul Office/IIMB/Projects/Manipal Hospital/Imputed Data/Manipal_Hospital_TrainingSet_ThreeClass_05012017.csv",head=TRUE,na.strings=c("", " ","#N/A", "NA"), sep=",")
raw.test.data <- read.csv("/Users/Rahul/Documents/Rahul Office/IIMB/Projects/Manipal Hospital/Imputed Data/Manipal_Hospital_TestSet_ThreeClass05012017.csv",head=TRUE,na.strings=c("", " ","#N/A", "NA"), sep=",")
#SL no, Hospital ID, CompanyName, State,CE_NPS
data.train <- raw.train.data[,c(-1,-2,-10,-48,-49,-51)]
data.test <- raw.test.data[,c(-1,-2, -10,-48,-49,-51)]
for (i in c(10:44)) {
if (is.numeric(data.train[,i])) {
data.train[,i] <- factor(data.train[,i],
levels = c(1,2,3,4), ordered = TRUE)
}
}
data.train[,46] <- factor(data.train[,46],
levels = c("Detractor","Passive","Promotor"), ordered = TRUE)
#sapply(12:54, function(x,y) if(is.factor(y[,x])) y[,x] <- factor(y[,x], levels = c("Blank","One","Two","Three","Four"), ordered = TRUE), y = filter.data)
str(data.train)
summary(data.train) #summary of the data
#filter.data$NPS_Status <- relevel(filter.data$NPS_Status, ref = "No")
data.test <- na.omit(data.test) # listwise deletion of missing
for (i in c(10:44)) {
if (is.numeric(data.test[,i])) {
data.test[,i] <- factor(data.test[,i],
levels = c(1,2,3,4), ordered = TRUE)
}
}
data.test[,46] <- factor(data.test[,46],
levels = c("Detractor","Passive","Promotor"), ordered = TRUE)
#sapply(12:54, function(x,y) if(is.factor(y[,x])) y[,x] <- factor(y[,x], levels = c(,"1","2","3","4"), ordered = TRUE), y = filter.data)
str(data.test)
summary(data.test) #summary of the data
#filter.data$NPS_Status <- relevel(filter.data$NPS_Status, ref = "No")
#remove variables leading to quasi complete seperation and the numeric variable for converting data into matrix. Column 8: Country has many levels with 1-2 entries leading to no predictive power for certain levels.
model.train <- data.train[,-c(2,6,8,10:17,39)]
#remove variables leading to quasi complete seperation and the numeric variable for converting data into matrix
model.test <- data.test[,-c(2,6,8,10:17,39)]
for (i in c(1:34)){
id = 0
if (is.factor(model.test[,i])) {
#id <- which(!(model.test[,i] %in% levels(model.train[,i])))
#model.test[,i][id] <- NA
model.test[,i] <- factor(model.test[,i], levels = levels(model.train[,i]))
}
}
#To remove new levels from test set
id <- which((model.test$NS_NURSEPROACTIVENESS == "1"))
model.test$NS_NURSEPROACTIVENESS[id] <- NA
model.test <- na.omit(model.test)
#Null Model
noModel <- polr(model.train$NPS_Status ~ 1,data = as.matrix(model.train), Hess =  TRUE, method = "logistic")
ordinal.model <- polr(model.train$NPS_Status ~., data = as.matrix(model.train), Hess =  TRUE, method = "logistic")
#Stepwise - Forward selection backward elimination
step.ordinal.model <- step(noModel, list(lower = formula(noModel),
upper =formula(ordinal.model)),
direction = "both",trace = 0)
## store table
(ctable <- exp(coef(summary(step.ordinal.model))))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
## combined table
(ctable <- cbind(ctable, "p value" = p))
## odds ratios
#exp(coef(ordinal.model))
summary(step.ordinal.model)
## store table
(ctable <- exp(coef(summary(step.ordinal.model))))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
## combined table
(ctable <- cbind(ctable, "p value" = p))
## odds ratios
#exp(coef(ordinal.model))
summary(step.ordinal.model)
predicted.scores.train <- predict(step.ordinal.model, model.train, type = "probs")
predicted.class.train <- predict(step.ordinal.model, model.train, type = "class")
table(model.train$NPS_Status, predicted.class.train)
#misclassification error
mean(as.character(model.train$NPS_Status) != as.character(predicted.class.train))
predicted.scores.test <- predict(step.ordinal.model, model.test, type = "probs")
predicted.class.test <- predict(step.ordinal.model, model.test, type = "class")
table(model.test$NPS_Status, predicted.class.test)
#misclassification error
mean(as.character(model.test$NPS_Status) != as.character(predicted.class.test))
model.train <- data.train[,-c(8)]
View(model.train)
model.train <- data.train[,-c(8)]
for (i in c(9:43)) {
if (is.ordered(model.train[,i])) {
model.train[,i] <- factor(model.train[,i], ordered = FALSE)
}
}
if (is.ordered(model.train[,45])) {
model.train[,45] <- factor(model.train[,45], ordered = FALSE)
}
str(model.train)
model.test <- data.test[,-c(8)]
for (i in c(9:43)) {
if (is.ordered(model.test[,i])) {
model.test[,i] <- factor(model.test[,i], ordered = FALSE)
}
}
if (is.ordered(model.test[,45])) {
model.test[,45] <- factor(model.test[,45], ordered = FALSE)
}
for (i in c(1:45)) {
id = 0
if (is.factor(model.test[,i])) {
#id <- which(!(model.test[,i] %in% levels(model.train[,i])))
#model.test[,i][id] <- NA
model.test[,i] <- factor(model.test[,i], levels = levels(model.train[,i]))
}
}
#To remove new levels from test set
id <- which((model.test$NS_NURSEPROACTIVENESS == "1"))
model.test$NS_NURSEPROACTIVENESS[id] <- NA
model.test <- na.omit(model.test)
str(model.test)
objControl <- trainControl(method='cv', number = 3,
returnResamp='none',
summaryFunction = defaultSummary,
savePredictions = TRUE,
classProbs = TRUE,
sampling = "down")#, p = 0.70) #in case method = #"LGOCV"
set.seed(4121)
rf.down.model <- train(model.train[,1:44], model.train[,45],
method='rf',
trControl=objControl,
metric = "Accuracy",ntree = 1024,
prox=TRUE,allowParallel=TRUE)
print(rf.down.model)
confusionMatrix.train(rf.down.model)
varImp(rf.down.model)
trainPredictedClass <- predict(rf.down.model, model.train, type = "raw")
confusionMatrix(trainPredictedClass,model.train$NPS_Status)
testPredictedClass <- predict(rf.down.model, model.test, type = "raw")
confusionMatrix(testPredictedClass,model.test$NPS_Status)
hsb2 = read.table('http://www.ats.ucla.edu/stat/data/hsb2.csv', header=T, sep=",")
View(hsb2)
hsb2$race.f = factor(hsb2$race, labels=c("Hispanic", "Asian", "African-Am", "Caucasian"))
View(hsb2)
tapply(hsb2$write, hsb2$race.f, mean)
library(ggplot2)
raw.data <- read.csv(file.choose(),header = T,
na.strings = c("", " ", "NA"), sep = ",",
stringsAsFactors = T)
filter.data <- raw.data
filter.data <- raw.data[complete.cases(raw.data),]
filter.data <- raw.data[,c(-1)]
View(raw.data)
View(filter.data)
n <- ncol(filter.data)
processed.data <- cbind(rep(1, nrow(filter.data)))
View(processed.data)
View(raw.data)
table(filter.data$CHK_ACCT)
table(filter.data$History)
a <- model.matrix(~filter.data[,1])
View(a)
n <- ncol(filter.data)
#for creating X0 variable
processed.data <- cbind(rep(1, nrow(filter.data)))
for (i in 1:n ) {
#i=2
if (is.factor(filter.data[,i])) {
#creating dummies for the factors and storing in temp
temp <- model.matrix(~filter.data[,i])
#removing the first column which is an intercept term in dummy coding
temp <- subset(temp, select = -c(1) )
#loop through to rename the column names appropriately
for (c in 1:ncol(temp)) {
str <- colnames(temp)[c]
colnames(temp)[c] <- sub("filter.data\\[, i\\]"," ",colnames(temp)[c])
colnames(temp)[c] <- paste(colnames(filter.data)[i], "- ", colnames(temp)[c])
}
#the factors after dummy variable creation is appeneded to the processed.data
processed.data <- cbind(processed.data,temp)
}
#in case not a factor, store the variable in processed.data directly
else {
processed.data <- cbind(processed.data,filter.data[,i])
len <- ncol(processed.data)
colnames(processed.data)[len] <- colnames(filter.data[i])
#standardize the numeric variable for faster descent. (Feature scaling)
processed.data[,len] <- scale(processed.data[,len])
}
}
View(processed.data)
x <- processed.data
y <- as.matrix(x[,ncol(x)])
View(y)
View(y)
colnames(y)[1] <- colnames(x)[ncol(x)]
x <- x[,c(-ncol(x))]
colnames(x)[1] <- "X0"
x <- as.matrix(x)
View(y)
View(x)
sigmoid <- function(z) {
1/(1 + exp(-z))
}
hypothesisLr <- function(theta, x) {
sigmoid(x %*% theta) #matrix multiplication (x is 1000*75 and theta is 75*1, result 75*1)
}
View(hypothesisLr)
View(sigmoid)
computeCost <- function(theta, x, y) {
m <- length(y)
s <- sapply(1:m, function(i)
y[i]*log(hypothesisLr(theta,x[i,])) + (1 - y[i])*log(1 - hypothesisLr(theta,x[i,]))
)
j <- -1/m * sum(s)
return(j)
}
gradAlgo <- function(theta, x, y) {
m <- length(y)
g <- 1/m * t(x) %*% (hypothesisLr(theta,x) - y)
return(g)
}
alpha <- 0.01 #learning rate 1
iter <- 100 #no of interations for descent 5000
theta <- rep(0, ncol(x))
computeCost(theta, x, y)
for (c in 1:iter) {
theta <- theta - alpha * gradAlgo(theta,x,y)
j[c] <- computeCost(theta,x,y)
}
j <- rep(0,iter) #to maintain log of cost
for (c in 1:iter) {
theta <- theta - alpha * gradAlgo(theta,x,y)
j[c] <- computeCost(theta,x,y)
}
j
alpha <- 1 #learning rate 1
iter <- 100 #no of interations for descent 5000
#m <- length(y)
theta <- rep(0, ncol(x))
#cost at intial theta
computeCost(theta, x, y)
j <- rep(0,iter) #to maintain log of cost
for (c in 1:iter) {
theta <- theta - alpha * gradAlgo(theta,x,y)
j[c] <- computeCost(theta,x,y)
}
j
alpha <- 100 #learning rate 1
iter <- 100 #no of interations for descent 5000
#m <- length(y)
theta <- rep(0, ncol(x))
#cost at intial theta
computeCost(theta, x, y)
j <- rep(0,iter) #to maintain log of cost
for (c in 1:iter) {
theta <- theta - alpha * gradAlgo(theta,x,y)
j[c] <- computeCost(theta,x,y)
}
j
alpha <- 10 #learning rate 1
iter <- 100 #no of interations for descent 5000
#m <- length(y)
theta <- rep(0, ncol(x))
#cost at intial theta
computeCost(theta, x, y)
j <- rep(0,iter) #to maintain log of cost
for (c in 1:iter) {
theta <- theta - alpha * gradAlgo(theta,x,y)
j[c] <- computeCost(theta,x,y)
}
j
alpha <- 0.1 #learning rate 1
iter <- 100 #no of interations for descent 5000
#m <- length(y)
theta <- rep(0, ncol(x))
#cost at intial theta
computeCost(theta, x, y)
j <- rep(0,iter) #to maintain log of cost
for (c in 1:iter) {
theta <- theta - alpha * gradAlgo(theta,x,y)
j[c] <- computeCost(theta,x,y)
}
ggplot() +
aes(x = 1:iter, y = j) +
geom_point(colour = "red") +
geom_path() + xlab("Iteration") +
ylab("Cost J")
alpha <- 0.01 #learning rate 1
iter <- 1000 #no of interations for descent 5000
#m <- length(y)
theta <- rep(0, ncol(x))
#cost at intial theta
computeCost(theta, x, y)
j <- rep(0,iter) #to maintain log of cost
for (c in 1:iter) {
theta <- theta - alpha * gradAlgo(theta,x,y)
j[c] <- computeCost(theta,x,y)
}
ggplot() +
aes(x = 1:iter, y = j) +
geom_point(colour = "red") +
geom_path() + xlab("Iteration") +
ylab("Cost J")
m <- nrow(y)
actual.y <- y
actual.y[actual.y == 0] <- "Bad"
actual.y[actual.y == 1] <- "Good"
predicted.y = rep("Bad", m);
predicted.y[hypothesisLr(theta,x) >= 0.5] = "Good";
addmargins(table(actual.y, predicted.y))
lg.glm <- glm(filter.data$Credit.classification ~ .,data = filter.data, family = "binomial")
summary(lg.glm)
lg.predict.prob.y <- predict(lg.glm, filter.data[,1:20],"response")
m <- length(filter.data[,21])
actual.y <- filter.data[,21]
predicted.y = rep("Bad", m);
predicted.y[lg.predict.prob.y >= 0.5] = "Good";
addmargins(table(actual.y, predicted.y))
theta
library(shiny)
runExample(“01_Hello”)
runExample("01_Hello")
library(rsconnect)
deployApp(hrmodel)
getwd()
setwd("/Users/Rahul/Shiny")
setwd("/Users/Rahul/shiny")
setwd("/Users/Rahul/ShinyR")
deployApp(hrmodel)
setwd("~/Documents/Rahul Office/IIMB/Work @ IIMB/Training Material/Concepts/R files")
runApp(demo)
runApp(demo.r)
runApp()
setwd("~/Documents/Rahul Office/IIMB/Work @ IIMB/Training Material/Concepts/R files/demo")
runApp()
deployApp(demo)
deployApp("demo")
rsconnect::accounts()
rsconnect::accountInfo()
setwd("~/Documents/Rahul Office/IIMB/Work @ IIMB/Training Material/Concepts/R files")
rsconnect::deployApp(demo)
rsconnect::deployApp("demo")
rsconnect::removeAccount("arima")
rsconnect::deployApp("demo")
setwd("\users\Rahul\ShinyR")
setwd("\Users\Rahul\ShinyR")
setwd("/Users/Rahul/ShinyR")
runApp(hrmodel)
runApp("hrmodel")
install.packages("DT")
runApp("hrmodel")
deployApp("hrmodel")
runApp("dashboard")
runApp("dashboard")
runApp("dashboard")
runApp("Shinydashboard")
runApp("baseline")
install.packages("psych")
runApp("baseline")
runApp("hrmodel")
deployApp("baseline")
rsconnect::applications()
rsconnect::terminateApp("baseline")
library(caret)            #for split and model accuracy
library(RANN)             #for KKNImpute
raw.data <- read.csv("/Users/Rahul/Documents/Rahul Office/IIMB/Projects/Manipal Hospital/Combined_Data_Numeric_Score_4212017.csv",head=TRUE,na.strings=c("", " ","#N/A", "NA"), sep=",")
set.seed(4121)
trainIndex <- createDataPartition(raw.data$NPS_Status, p = 0.70, list=FALSE)
data.train <- raw.data[ trainIndex,]
data.test <- raw.data[-trainIndex,]
#write.csv(na.omit(data.test),"Manipal_Hospital_TestSet_04232017.csv")
count(complete.cases(data.train))
length(complete.cases(data.train))
complete.cases(data.train)
sum(complete.cases(data.train))
28*28
29*29
?preProcess
library(rsconnect)
getwd()
runExample("01_Hello")
?pam
library(caret)            #for split and model accuracy
library(RANN)             #for KKNImpute
raw.data <- read.csv("/Users/Rahul/Documents/Rahul Office/IIMB/Projects/Manipal Hospital/Combined_Data_Numeric_Score_4212017.csv",head=TRUE,na.strings=c("", " ","#N/A", "NA"), sep=",")
set.seed(4121)
trainIndex <- createDataPartition(raw.data$NPS_Status, p = 0.70, list=FALSE)
data.train <- raw.data[ trainIndex,]
data.test <- raw.data[-trainIndex,]
#write.csv(na.omit(data.test),"Manipal_Hospital_TestSet_04232017.csv")
sum(complete.cases(data.train))
#data.train <- data.train[-1]
preProcValues <- preProcess(data.train[,2:51], method = c("knnImpute"),
k = 28,
knnSummary = mean)
impute.train <- predict(preProcValues, data.train,na.action = na.pass)
#To get the original data
AgeYrs <- impute.train$AgeYrs*preProcValues$std[1]+preProcValues$mean[1]
Estimatedcost <- impute.train$Estimatedcost *preProcValues$std[2]+preProcValues$mean[2]
LengthofStay <- impute.train$LengthofStay *preProcValues$std[38]+preProcValues$mean[38]
CE_NPS <- impute.train$CE_NPS *preProcValues$std[39]+preProcValues$mean[39]
survey.list <- lapply(12:46, function(x) ceiling(impute.train[x]*preProcValues$std[x-9]+preProcValues$mean[x-9]))
imputed.data <- data.frame(data.train[,1:2],
AgeYrs,
data.train[,4:6],
Estimatedcost,
data.train[,8:11],
survey.list,
data.train[,47:48],
LengthofStay,
CE_NPS,
data.train[51])
#write.csv(imputed.data,"Manipal_Hospital_TrainingSet_04232017.csv")
View(data.train)
View(impute.train)
View(imputed.data)
library(shiny)
runExample("01_Hello")
runExample("07_widgets")
rsconnect::accounts()
deployApp("dashboard")
